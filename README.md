# Vulnerability of Natural Language Classifiers to Evolutionary Generated Adversarial Text

## ToDo (last updated: 2021W44)
- [Mohamed] Paper section 2 (related work) + investigating implementaiton
- [Sandy] Paper section 5 (results) + investigating implementaiton
- [Mani] Check sections 3-5 for other resources (refs, datasets, etc...) 
---
## Datasets
- [IMDB link1](https://datasets.imdbws.com) -- [IMDB link2](http://ai.stanford.edu/~amaas/data/sentiment/)
- [Yelp link1](https://www.yelp.com/dataset) -- [Yelp link2](https://www.kaggle.com/yelp-dataset/yelp-dataset)
- [FAKE](https://www.kaggle.com/c/fake-news/data)
- [AG News](http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html)
- [GLUE](https://gluebenchmark.com)
---
### Implementations
- [BERT-Attack](https://github.com/LinyangLee/BERT-Attack) [^1]
- [TextFooler](https://github.com/jind11/TextFooler) [^2]
---
### Colab notebooks
- 
---
## Refs
- [HuggingFace - Datasets](https://huggingface.co/datasets)
- [PapersWithCode - Datasets](https://paperswithcode.com/task/text-classification)

---

[^1]: Li, Linyang, Ruotian Ma, Qipeng Guo, Xiangyang Xue, and Xipeng Qiu. "BERT-ATTACK: Adversarial Attack against BERT Using BERT." In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 6193-6202. 2020.
[^2]: Jin, Di, Zhijing Jin, Joey Tianyi Zhou, and Peter Szolovits. "Is bert really robust? a strong baseline for natural language attack on text classification and entailment." In Proceedings of the AAAI conference on artificial intelligence, vol. 34, no. 05, pp. 8018-8025. 2020.
